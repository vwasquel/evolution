{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
    "\n",
    "\n",
    "# Evolutionary Computation\n",
    "\n",
    "## 2.1 Genetic Algorithms\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://d9w.github.io/evolution/\">https://d9w.github.io/evolution/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. [Genetic Algorithm Overview](#overview)\n",
    "2. [Initialization](#populations)\n",
    "3. [Selection](#selection)\n",
    "4. [Mutation](#mutation)\n",
    "5. [Crossover](#crossover)\n",
    "6. [Putting it all together](#together)\n",
    "7. [Elitism](#elitism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"overview\"></a>Genetic Algorithm Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall the outline of evolutionary algorithms that we discussed in section 1.2. The outline of an evolutionary algorithm is to start with an initial population and then to iterate through a cycle of evaluation, selection, and modification, passing the modified population on as the next generation.\n",
    "\n",
    "<img src=\"../imgs/AlgoG.png\">\n",
    "\n",
    "This is the underlying algorithm of a genetic algorithm. This term is general and can cover a variety of more specific algorithms such as NSGA-II and NEAT, but in this section we'll discuss a classic genetic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The defining features of a classic genetic algorithm are a large population initialized at random and the mutation and crossover operators during the modification step. In a classic GA, we will use a selection method to randomly select two individuals from the population, combine them using crossover, mutate the resulting individual, and add it to the new population. We will repeat this until the new population is full. Let's write that basic outline as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "abstract type Individual end\n",
    "\n",
    "function step_ga(population::Array{<:Individual})\n",
    "    evaluate!(population)\n",
    "    max_fit = maximum([i.fitness for i in population])\n",
    "    \n",
    "    new_population = Array{Individual}(undef, 0)\n",
    "    while length(new_population) < length(population)\n",
    "        parent1 = select(population)\n",
    "        parent2 = select(population)\n",
    "        child1 = crossover(parent1, parent2)\n",
    "        child1 = mutate(child1)\n",
    "        push!(new_population, child1)\n",
    "    end\n",
    "    \n",
    "    new_population, max_fit\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We've defined a single step of the genetic algorithm and can fill in the functions later. Let's now define the full evolution, keeping track of the maximum fitness in the population at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function ga(n_generations::Int)\n",
    "    population = initialize()\n",
    "    fits = zeros(n_generations)\n",
    "    \n",
    "    for i in 1:n_generations\n",
    "        population, max_fit = step_ga(population)\n",
    "        fits[i] = max_fit\n",
    "    end\n",
    "    \n",
    "    fits\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"initialization\"></a>Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Earlier we saw a new bit of Julia:\n",
    "```\n",
    "abstract type Individual end\n",
    "```\n",
    "This let us use the type `Array{Individual}` in our function definition even though a concrete definition of `Individual` hasn't been used yet. In the last notebook, we had to redefine functions in order to switch between the boolean `Individual` and the `FloatIndividual`.  Abstract types let us define functions which can work for either type, as long as they are subtypes of this abstract. This is known as multiple dispatch and we'll use it to define the later parts of our genetic algorithm. Let's define our two `Individual` types for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mutable struct BitInd <: Individual\n",
    "    genes::BitArray\n",
    "    fitness::Float64\n",
    "end\n",
    "\n",
    "function BitInd(n::Int)\n",
    "    BitInd(bitrand(n), -Inf)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mutable struct FloatInd <: Individual\n",
    "    genes::Array{Float64}\n",
    "    fitness::Float64\n",
    "end\n",
    "\n",
    "function FloatInd(n::Int)\n",
    "    FloatInd(rand(n), -Inf)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This will be very useful later, but for now just remember that we still have our two different types, `BitInd` and `FloatInd`, but that we can refer to both using `Individual`. Let's create population initialization methods for these two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function bit_init(population_size::Int, n::Int)\n",
    "    [BitInd(n) for i in 1:population_size]\n",
    "end\n",
    "\n",
    "function float_init(population_size::Int, n::Int)\n",
    "    [FloatInd(n) for i in 1:population_size]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see our different populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "population = bit_init(100, 4)\n",
    "population[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "population = float_init(100, 4)\n",
    "population[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"populations\"></a>Evaluation\n",
    "\n",
    "The first part of the genetic algorithm step is the evaluation. We'll look at two evaluation functions, one for our binary individual type, and one for the floating point individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looking at our genetic algorithm implementation, we use an `evaluate!` function to evaluate the entire population. Let's write that general function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function evaluate!(population::Array{<:Individual})\n",
    "    for i in population\n",
    "        i.fitness = objective(i)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note the `<:Individual` in our definition of `population`. This means that population is expected to be an `Array` of any subtype of `Individual`, meaning `BitInd` or `FloatInd`. This evaluate function will work for both types then. Let's write individual objective functions for these two different types. For the binary type, we'll use the OneMax function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function objective(i::BitInd)\n",
    "    sum(i.genes)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's test that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "population = bit_init(10, 4)\n",
    "evaluate!(population)\n",
    "print([i.fitness for i in population])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a floating point problem, let's look at something a bit more difficult than the sphere problem. Specifically, we'll use the [Rastrigin function](https://en.wikipedia.org/wiki/Test_functions_for_optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rastrigin(x) = 10*length(x) .+ sum(x.^2 .- 10 .* cos.(2*pi*x))\n",
    "\n",
    "x = -5:0.1:5\n",
    "y = -5:0.1:5\n",
    "fz(x, y) = rastrigin([x, y])\n",
    "plot(plot(x, y, fz, st=:surface), plot(x, y, fz, st=:contour), size = (800, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll use a smaller section of the rastrigin function for demonstration, but you can also try the Genetic Algorithm on the entire space as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = 0:0.01:1\n",
    "y = 0:0.01:1\n",
    "fz(x, y) = -rastrigin([x*5-2, y*5-2])\n",
    "#fz(x, y) = exp(-rastrigin([x*5-2, y*5-2]))\n",
    "plot(plot(x, y, fz, st=:surface), plot(x, y, fz, st=:contour), size = (800, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's define our second objective function using this. Note that we'll also just call it `objective`, like the one we defined before. However, we'll be making a second function which applies to the `FloatInd` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function objective(i::FloatInd)\n",
    "    -rastrigin(i.genes .* 5 .- 2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see the different functions we've defined used `methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "methods(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see what our first population of floating point individuals looks like in the Rastrigin function **search space**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "population = float_init(100, 10)\n",
    "xs = [i.genes[1] for i in population]\n",
    "ys = [i.genes[2] for i in population]\n",
    "plot(x, y, fz, st=:contour)\n",
    "scatter!(xs, ys, label=\"pop\", legend=:none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we can see, having a large population of individuals means we have a chance of already starting out in a good position. However, some others might be in **local maxima** - points which are higher than the areas around them, but not the **global maximum**. These points can be deceptive if we tend to select only the individuals in high points. What we want to do with selection in a genetic algorithm is maintain **diversity** while moving towards the **global maximum**. Let's see how we can do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise 1</b>\n",
    "    <br/>\n",
    "Visualize the sphere function from the first class. Why do you think the Rastrigin function is more difficult than the sphere function? Is there any other function which looks more difficult?\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"selection\"></a>Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which individuals should pass on their genetic information to the next generation? We could imagine a simple schemes of taking the best individuals globally, say 20% of them, and mutating each of these experts for the next generation. In a simple problem like this one, such a method might work. However, we would lose important genetic diversity, one of the main advantages of our large population. Let's explore some different selection methods. To do so, we'll need to evaluate all individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For this first proposed method of taking the top individuals, which is called **truncation selection**, we'll need to order them. In Julia, we can override any function, including the basic functions of the language. To order our population, we can use the main `sort!` method, which relies on being able to compare individuals using `<`. So let's make a new definition for the `<`, or `isless`, function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import Base.isless\n",
    "\n",
    "function isless(i1::Individual, i2::Individual)\n",
    "    i1.fitness < i2.fitness\n",
    "end\n",
    "evaluate!(population)\n",
    "println(population[1])\n",
    "println(population[2])\n",
    "println(population[1] < population[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that we have a way of comparing individuals, we can order lists of them using the `sort!` function. We'll sort from biggest to smallest to have the best individuals at the beginning of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "population = float_init(100, 2)\n",
    "evaluate!(population)\n",
    "fits = [i.fitness for i in population]\n",
    "println(\"First: \", population[1].fitness, \", last :\", population[end].fitness)\n",
    "println(\"Max: \", maximum(fits), \", min: \", minimum(fits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sort!(population, rev=true)\n",
    "println(\"First: \", population[1].fitness, \", last :\", population[end].fitness)\n",
    "println(\"Max: \", maximum(fits), \", min: \", minimum(fits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot where our best individuals are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xs = [i.genes[1] for i in population]; ys = [i.genes[2] for i in population]\n",
    "plot(x, y, fz, st=:contour)\n",
    "scatter!(xs[21:end], ys[21:end], label=\"pop\", legend=:outerright)\n",
    "scatter!(xs[1:20], ys[1:20], label=\"experts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As we can see, using this selection method, we risk optimizing towards local maxima, especially if we completely discard the rest of the population. Let's look at other selection methods for now, and we'll keep truncation selection in mind for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will instead assign a probability to each individual based on their fitness. This is known as **fitness proportionate selection**. Specifically, we will use the probability\n",
    "\n",
    "$p_i = \\frac{f_i}{\\sum_{j=1}^N f_j}$\n",
    "\n",
    "The probability is each fitness divided by the sum. We'll use the `.` dot broadcast operator in Julia to divide each element of `fits` by the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fits = [i.fitness for i in population]\n",
    "p = fits ./ sum(fits);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "histogram(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use these weights to sample from our population using the `sample` function from the `StatsBase` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample(population, Weights(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's write this according to the `select` function definition we used before, which takes in the population and gives out a single individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function fp_select(population::Array{<:Individual})\n",
    "    fits = [-i.fitness for i in population]\n",
    "    fits = maximum(fits) .- fits\n",
    "    p = fits ./ sum(fits)\n",
    "    sample(population, Weights(p))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Does this perform better than our previous method? Let's select 20 individuals using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "selected = Array{Individual}(undef, 20)\n",
    "for i in eachindex(selected)\n",
    "    selected[i] = fp_select(population)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sxs = [i.genes[1] for i in selected]\n",
    "sys = [i.genes[2] for i in selected]\n",
    "xs = [i.genes[1] for i in population]\n",
    "ys = [i.genes[2] for i in population]\n",
    "plot(x, y, fz, st=:contour)\n",
    "scatter!(xs, ys, label=\"pop\", legend=:outertopright)\n",
    "scatter!(sxs, sys, label=\"fp_select\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we can see here, individuals are not only found in local maxima but throughout the search space, which is good for diversity. The last selection method we'll use is called tournament selection. This method creates small random tournaments and selects the winner from this smaller subset for every new individual. We'll use a tournament size of 3, so we'll randomly select 3 individuals and then return the best individual from those 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function tournament_select(population::Array{<:Individual})\n",
    "    tournament = sample(population, 3)\n",
    "    sort!(tournament, rev=true)[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at 20 selections from the tournament selection method and compare it to the fitness proportionate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "winners = Array{Individual}(undef, 20)\n",
    "for i in eachindex(winners)\n",
    "    winners[i] = tournament_select(population)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wxs = [i.genes[1] for i in winners]\n",
    "wys = [i.genes[2] for i in winners]\n",
    "p1 = plot(x, y, fz, st=:contour)\n",
    "scatter!(xs, ys, legend=:none)\n",
    "scatter!(sxs, sys)\n",
    "title!(\"Fitness Proportionate\")\n",
    "p2 = plot(x, y, fz, st=:contour)\n",
    "scatter!(xs, ys, legend=:none)\n",
    "scatter!(wxs, wys)\n",
    "title!(\"Tournament\")\n",
    "plot(p1, p2, size=(950, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise 2</b>\n",
    "    <br/>\n",
    "    Plot the histogram of fitness values of 100 selected individuals using these two methods, and using a larger $n$ value. How do the distributions from the two methods compare? Try it also for a population of binary individuals on the OneMax function. Finally, try increasing the tournament size. What effect does that have on the selected individuals' fitness distribution?\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"mutation\"></a>Mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For this genetic algorithm, we'll simply reuse the functions we defined in section 1.3. We will flip the gene bit for binary individuals and use `rand` for floating point individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function mutate(ind::BitInd; mutation_rate::Float64=1.0/length(ind.genes))\n",
    "    new_genes = copy(ind.genes)\n",
    "    for i in eachindex(new_genes)\n",
    "        if rand() < mutation_rate\n",
    "            new_genes[i] = ~ind.genes[i]\n",
    "        end\n",
    "    end\n",
    "    BitInd(new_genes, -Inf)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function mutate(ind::FloatInd; mutation_rate::Float64=1.0/length(ind.genes))\n",
    "    new_genes = copy(ind.genes)\n",
    "    for i in eachindex(new_genes)\n",
    "        if rand() < mutation_rate\n",
    "            new_genes[i] = rand()\n",
    "        end\n",
    "    end\n",
    "    FloatInd(new_genes, -Inf)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(population[1])\n",
    "println(mutate(population[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise 3</b>\n",
    "    <br/>\n",
    "    Our mutation operator samples from the entire space. Can we instead use the previous gene value as a starting point for mutation? Implement a new mutation operator that adds a small random value between -0.1 and 0.1 to the modified gene.\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"crossover\"></a>Crossover\n",
    "\n",
    "Considering we have such a large population, is there some way to combine individual solutions to lead to better solutions? For example, could we make an individual which inherits information from two parent individuals? This is the idea behind crossover, the other operator in genetic algorithms besides mutation. It is based on sexual reproduction where the genetic information of two parent individuals is mixed to create an offspring individual. The idea of combining the information from multiple individuals together to create the next generation is something we'll explore in more detail next class when discussing evolutionary strategies. For now, let's look at ways to combine two individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../imgs/crossover.png\" width=\"80%\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first methods we'll look at is single-point crossover. Here, the child genes are composed of two continuous sections, the first from one parent and the second from the other parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function one_point_crossover(p1::Individual, p2::Individual)\n",
    "    child = copy(p1.genes)\n",
    "    n = rand(1:length(p2.genes))\n",
    "    child[n:end] = copy(p2.genes[n:end])\n",
    "    typeof(p1)(child, -Inf)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's test that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p1 = BitInd(15)\n",
    "p2 = BitInd(15)\n",
    "println(\"P1: \", p1)\n",
    "println(\"P2: \", p2)\n",
    "child = one_point_crossover(p1, p2)\n",
    "println(\"C : \", child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is most useful when sequential sections of a genome should be passed together, which is the case in biological evolution but not always necessary in artificial evolution. This method is also the basis of k-point crossover, which follows the same method but splits at $k$ points, alternating between parents at each crossing point. Note that this method can generate two children at once, but for the sake of coherence we'll just use the first child."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The second crossover method we'll look at is uniform crossover, which randomly chooses a different parent for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function uniform_crossover(p1::Individual, p2::Individual)\n",
    "    child = copy(p1.genes)\n",
    "    for i in eachindex(child)\n",
    "        if rand() < 0.5\n",
    "            child[i] = p2.genes[i]\n",
    "        end\n",
    "    end\n",
    "    typeof(p1)(child, -Inf)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p1 = BitInd(15)\n",
    "p2 = BitInd(15)\n",
    "println(\"P1: \", p1)\n",
    "println(\"P2: \", p2)\n",
    "child = one_point_crossover(p1, p2)\n",
    "println(\"C : \", child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise 4</b>\n",
    "    <br/>\n",
    "    Which crossover method do you expect to work better for the OneMax problem? What about for the Rastrigin function? Explain your reasoning.\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"together\"></a>Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look back at the functions we defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function step_ga(population::Array{<:Individual})\n",
    "    evaluate!(population)\n",
    "    max_fit = maximum([i.fitness for i in population])\n",
    "    \n",
    "    new_population = Array{Individual}(undef, 0)\n",
    "    while length(new_population) < length(population)\n",
    "        parent1 = select(population)\n",
    "        parent2 = select(population)\n",
    "        child1 = crossover(parent1, parent2)\n",
    "        child1 = mutate(child1)\n",
    "        push!(new_population, child1)\n",
    "    end\n",
    "    \n",
    "    new_population, max_fit\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function ga(n_generations::Int)\n",
    "    population = initialize()\n",
    "    fits = zeros(n_generations)\n",
    "    \n",
    "    for i in 1:n_generations\n",
    "        population, max_fit = step_ga(population)\n",
    "        fits[i] = max_fit\n",
    "    end\n",
    "    \n",
    "    fits\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to define our function choices for `initialize`, `select`, and `crossover`. Let's focus on the Rastrigin function and use uniform crossover. We'll compare the two selection methods, starting with fitness proporitionate selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "initialize() = float_init(100, 10)\n",
    "crossover = uniform_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "select = fp_select\n",
    "fits_fp = zeros(100, 10)\n",
    "for i in 1:10\n",
    "    fits_fp[:, i] = ga(100)\n",
    "    println(i, \" \", fits_fp[end, i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "select = tournament_select\n",
    "fits_tourney = zeros(100, 10)\n",
    "for i in 1:10\n",
    "    fits_tourney[:, i] = ga(100)\n",
    "    println(i, \" \", fits_tourney[end, i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "μ_fp = mean(fits_fp, dims=2)\n",
    "σ_fp = std(fits_fp, dims=2)\n",
    "μ_tourney = mean(fits_tourney, dims=2)\n",
    "σ_tourney = std(fits_tourney, dims=2)\n",
    "plot(μ_fp, ribbon=σ_fp, label=\"FP\", legend=:outertopright)\n",
    "plot!(μ_tourney, ribbon=σ_tourney, label=\"Tournament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While the randomness of tournament selection may appear disadvantageous, the diversity it provides in the search allows us to continue looking through new areas where we might get stuck with fitness proportionate selection. Tournament selection also gaurantees improvement by selecting individuals that are at least better than two other individuals in the population, while fitness proportionate selection may randomly choose bad individuals often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our results seem to fluctuate quite a bit. Why is that? We didn't see that before with the $(1+1)$ and $(1+\\lambda)$ EAs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a id=\"elitism\"></a>Elitism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An advantage that the $(1+1)$ and $(1+\\lambda)$ EAs have over the genetic algorithm we've coded here is that their convergence is **monotonically increasing**. This means as evolution goes on, the result will only improve and never get worse. This is because the best fitness is only ever removed when the expert is replaced by an equally good or better individual. However, neither of the selection methods we compared have this guarantee: the best individual can leave the population easily! While completely basing our selection on global competition may not be a good practice, we do want to keep at least the best individual. This is known as **elitism** and is the practice of directly passing on a certain number of individuals *without mutation* into the next generation. This is similar to the truncation selection we used at the beginning, but the individuals selected from truncation selection will bypass the modification step entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_elites = 5\n",
    "select = tournament_select\n",
    "\n",
    "function step_ga(population::Array{<:Individual})\n",
    "    evaluate!(population)\n",
    "    sort!(population, rev=true)\n",
    "    max_fit = maximum([i.fitness for i in population])\n",
    "    \n",
    "    new_population = Array{Individual}(undef, 0)\n",
    "    append!(new_population, population[1:num_elites])\n",
    "    while length(new_population) < length(population)\n",
    "        parent1 = select(population)\n",
    "        parent2 = select(population)\n",
    "        child1 = crossover(parent1, parent2)\n",
    "        child1 = mutate(child1)\n",
    "        push!(new_population, child1)\n",
    "    end\n",
    "    \n",
    "    new_population, max_fit\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "select = fp_select\n",
    "fits_fp = zeros(100, 10)\n",
    "for i in 1:10\n",
    "    fits_fp[:, i] = ga(100)\n",
    "    println(i, \" \", fits_fp[end, i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "select = tournament_select\n",
    "fits_tourney = zeros(100, 10)\n",
    "for i in 1:10\n",
    "    fits_tourney[:, i] = ga(100)\n",
    "    println(i, \" \", fits_tourney[end, i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "μ_fp = mean(fits_fp, dims=2)\n",
    "σ_fp = std(fits_fp, dims=2)\n",
    "μ_tourney = mean(fits_tourney, dims=2)\n",
    "σ_tourney = std(fits_tourney, dims=2)\n",
    "plot(μ_fp, ribbon=σ_fp, label=\"FP\", legend=:outertopright)\n",
    "plot!(μ_tourney, ribbon=σ_tourney, label=\"Tournament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise 5</b>\n",
    "    <br/>\n",
    "We now have many parameter choices: population size, mutation function, mutation rate, tournament size if using tournament selection, crossover function, number of elites. Using a maximum of 10000 <b>evaluations</b> (ie 100 generations with a population of 100), compare these parameter choices. What is the best value you can reach with $n=10$? Do the parameter results you get generalize to higher values of $n$? The best value should include the average and standard deviation over multiple runs.\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise 6</b>\n",
    "    <br/>\n",
    "Run the same analysis for the binary problem OneMax. Compare this result to the $(1+1)$ and $(1+\\lambda)$ EAs from the first class. Which method is the best?\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
