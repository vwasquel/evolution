{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
    "\n",
    "\n",
    "# Evolutionary Computation\n",
    "\n",
    "## 5.3 Deep Neuroevolution\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://d9w.github.io/evolution/\">https://d9w.github.io/evolution/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neuroevolution\n",
    "\n",
    "Artificial neural networks are commonly used today in many applications, from phone apps to automatic piloting systems to search engines. These machine learning models contain many parameters and are usually optimized with stochastic gradient descent. However, evolutionary strategies can also be a great tool for optimizing neural network parameters, especially when there isn't a clear direction the training of the network should take. This is the case for reinforcement learning, so we'll look at a classic RL task in this section.\n",
    "\n",
    "Because of the success of deep learning, where neural network architectures are \"deep\" by having many layers, this field is sometimes called deep neuroevolution. However, remember from tutorial 4 that researchers have been evolving neural networks long before the advent of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In today's notebook, I'll be using some Python RL environments and using PyCall to interact with them in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Conda.add(\"gym\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I'll also select a random seed. This means that whenever I generate random numbers, they'll follow a defined sequence. Finally, I'll import all of the code from the CMA-ES notebook, which I've put in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import Random\n",
    "Random.seed!(1234);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "include(\"cmaes.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's make a simple neural network. Remember the model of a neuron which multiplies inputs by synaptic weights then adds a bias. We'll construct a network with two internal, or hidden, layers. These layers will be fully connected - every neuron will connect to every other one in the next layer.\n",
    "\n",
    "<img src=\"../imgs/neuron_model.jpeg\" width=\"50%\">\n",
    "<img src=\"../imgs/cnn.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "struct FCLayer\n",
    "    w::Array{Float64}\n",
    "    b::Array{Float64}\n",
    "end\n",
    "\n",
    "struct SimpleANN\n",
    "    l1::FCLayer\n",
    "    l2::FCLayer\n",
    "    out::FCLayer\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can write a construction method which just uses zeros as all weights and biases. We'll fill these with the genetic information later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function SimpleANN(input::Int, N1::Int, N2::Int, output::Int)\n",
    "    l1 = FCLayer(zeros(N1, input), zeros(N1))\n",
    "    l2 = FCLayer(zeros(N2, N1), zeros(N2))\n",
    "    out = FCLayer(zeros(output, N2), zeros(output))\n",
    "    SimpleANN(l1, l2, out)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, we'll use our network to compute, passing an input in before the first layer and recording the activation of the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ann = SimpleANN(5, 64, 64, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function compute(inputs::Array{Float64}, ann::SimpleANN)\n",
    "    x = ann.l1.w * inputs .+ ann.l1.b\n",
    "    x = ann.l2.w * x .+ ann.l2.b\n",
    "    x = ann.out.w * x .+ ann.out.b\n",
    "    x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since all weights and biases are zeros, if we pass in zeros we should also get out zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "compute(zeros(5), ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have an ANN, let's test it. We'll evaluate individuals in the CartPole environment, where they must balance a pole on a cart to keep it upright. The actions our agent can take are to move the cart either right or left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gym = pyimport(\"gym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "n_in = 4\n",
    "n_out = 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll run an entire episode, which terminates whenever the pole falls to a certain angle from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function play_env(ann::SimpleANN; render=false)\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    env.seed(0)\n",
    "    obs = env.reset()\n",
    "    total_reward = 0.0\n",
    "    done = false\n",
    "    \n",
    "    while ~done\n",
    "        action = argmax(compute(obs, ann))-1\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        if render\n",
    "            env.render()\n",
    "        end\n",
    "        total_reward += reward\n",
    "    end\n",
    "    env.close()\n",
    "    env = nothing\n",
    "    Base.GC.gc()\n",
    "    total_reward\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With our zero network, this won't be able to last very long, as it is always taking a constant action of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ann = SimpleANN(n_in, 5, 5, n_out)\n",
    "play_env(ann; render=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's write a new constructor for our network which takes in genes and sets all of the network parameters. We'll then optimize these genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function SimpleANN(genes::Array{Float64})\n",
    "    ann = SimpleANN(n_in, 5, 5, n_out)\n",
    "    layers = [ann.l1.w, ann.l1.b, ann.l2.w, ann.l2.b, ann.out.w, ann.out.b]\n",
    "    L = 1\n",
    "    j = 1\n",
    "    for i in eachindex(genes)\n",
    "        if j > length(layers[L])\n",
    "            L += 1\n",
    "            j = 1\n",
    "        end\n",
    "        layers[L][j] = genes[i]\n",
    "        j += 1\n",
    "    end\n",
    "    ann\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The objective function is then just to create an ANN and evaluate its performance on an episode of the CartPole benchmark. Because CMA-ES is minimizing, we'll return the negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function objective(genes::Array{Float64})\n",
    "    ann = SimpleANN(genes)\n",
    "    -play_env(ann)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how many genes we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = n_in*5 + 5 + 5*5 + 5 + 5*n_out + n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can try a random individual, maybe it will do better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ann = SimpleANN(randn(N))\n",
    "play_env(ann; render=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use the CMAES function we defined in the last notebook and optimize for just a few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "c = CMAES(N=N, µ=10, λ=30, τ=sqrt(N), τ_c=N^2, τ_σ=sqrt(N))\n",
    "for i in 1:5\n",
    "    step!(c, objective)\n",
    "    println(i, \" \", maximum(.-c.F_λ))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We might notice that our results go down. Remember that CMA-ES is not elitist! We should keep an external archive of the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "best = nothing\n",
    "best_fit = -Inf\n",
    "c = CMAES(N=N, µ=10, λ=30, τ=sqrt(N), τ_c=N^2, τ_σ=sqrt(N))\n",
    "for i in 1:20\n",
    "    step!(c, objective)\n",
    "    bestind = argmin(c.F_λ)\n",
    "    maxfit = -c.F_λ[bestind]\n",
    "    println(i, \" \", maxfit)\n",
    "    if maxfit > best_fit\n",
    "        best = copy(c.offspring[bestind])\n",
    "        best_fit = maxfit\n",
    "    end\n",
    "    if best_fit == 500\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, we can see how the CMA-ES optimized invidual does on this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ann = SimpleANN(best)\n",
    "play_env(ann; render=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>\n",
    "    <br/>\n",
    "    We were sort of cheating before. This neural network only learned how to do well on one individual, the one which comes from seeing the environment with 0. Test is on an environment with a different seed. Does it still do well? Finally, re-run the evaluation, but don't use a random seed, or change it every time. What is the impact of a stochastic fitness on evolution?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
