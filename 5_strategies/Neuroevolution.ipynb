{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://github.com/d9w/evolution/raw/master/imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
    "\n",
    "\n",
    "# Evolutionary Algorithms\n",
    "\n",
    "## Evolving Neural Networks with ES\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://d9w.github.io/evolution/\">https://d9w.github.io/evolution/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to visualize the environment in this notebook, you will need to install the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install cma pyvirtualdisplay gym[box2d] pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <a name=\"neuroevolution\">3.</a> ES for Neuroevolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evolutionary strategies are intended for continuous optimization and can easily be applied to the optimization of neural network parameters, or *neuroevolution*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.l1 = nn.Linear(input_shape, 32)\n",
    "        self.l2 = nn.Linear(32, 32)\n",
    "        self.lout = nn.Linear(32, n_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x.float()))\n",
    "        x = F.relu(self.l2(x))\n",
    "        return self.lout(x)\n",
    "    \n",
    "    def get_params(self):\n",
    "        p = np.empty((0,))\n",
    "        for n in self.parameters():\n",
    "            p = np.append(p, n.flatten().cpu().detach().numpy())\n",
    "        return p\n",
    "    \n",
    "    def set_params(self, x):\n",
    "        start = 0\n",
    "        for p in self.parameters():\n",
    "            e = start + np.prod(p.shape)\n",
    "            p.data = torch.FloatTensor(x[start:e]).reshape(p.shape)\n",
    "            start = e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll add some visualization functionality to have the environment render directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pydisplay = Display(visible=0, size=(1400, 900))\n",
    "pydisplay.start()\n",
    "plt.ion();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Following the framework of evolutionary policy search, we will optimize a neural network representing a policy and maximize the total reward over a single episode using this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(ann, env, visul=True):\n",
    "    obs, info = env.reset(seed=0)\n",
    "    if visul:\n",
    "        img = plt.imshow(env.render())\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        # Output of the neural net\n",
    "        net_output = ann(torch.tensor(obs))\n",
    "        # the action is the value clipped returned by the nn\n",
    "        action = net_output.data.cpu().numpy().argmax()\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if visul:\n",
    "            img.set_data(env.render())\n",
    "            plt.axis('off')\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We've configured this for discrete action spaces. We can see a random neural network on different environments like `CartPole-v0`, `MountainCar-v0`, and `LunarLander-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2', render_mode=\"rgb_array\")\n",
    "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ann, env, visul=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to evolve the parameters of this neural network, we will modify the parameters of the network using `set_params` with the genes of the new individual. In the evolutionary literature, this is referred to as a *direct encoding* as the neural network parameters are directly encoded in the genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def fitness(x, ann, env, visul=False):\n",
    "    ann.set_params(x)\n",
    "    return -evaluate(ann, env, visul=visul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p = ann.get_params()\n",
    "np.shape(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can first observe a random individual $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(len(p))\n",
    "-fitness(x, ann, env, visul=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try optimizing the policy using the simple $(\\mu, \\lambda)$ ES we proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def mu_lambda(x, fitness, gens=200, lam=10, alpha=0.2, verbose=False):\n",
    "    x_best = x\n",
    "    f_best = fitness(x)\n",
    "    fits = np.zeros(gens)\n",
    "    for g in range(gens):\n",
    "        N = np.random.normal(size=(lam, len(x)))\n",
    "        F = np.zeros(lam)\n",
    "        for i in range(lam):\n",
    "            ind = x + N[i, :]\n",
    "            F[i] = fitness(ind)\n",
    "            if F[i] < f_best:\n",
    "                f_best = F[i]\n",
    "                x_best = ind\n",
    "                if verbose:\n",
    "                    print(g, \" \", f_best)\n",
    "        fits[g] = f_best\n",
    "        mu_f = np.mean(F)\n",
    "        std_f = np.std(F)\n",
    "        A = F\n",
    "        if std_f != 0:\n",
    "            A = (F - mu_f) / std_f\n",
    "        x = x - alpha * np.dot(A, N) / lam\n",
    "    return fits, x_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(654)\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)\n",
    "x = np.random.randn(len(ann.get_params()))\n",
    "f = lambda x : fitness(x, ann, env)\n",
    "fits, x = mu_lambda(x, f, gens=10, lam=10, alpha=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fits);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "-fitness(x, ann, env, visul=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMA-ES for Neuroevolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will now use CMA-ES for the Lunar Lander problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import cma\n",
    "np.random.seed(123)\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)\n",
    "es = cma.CMAEvolutionStrategy(len(ann.get_params()) * [0], 0.1, {'seed': 123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    solutions = np.array(es.ask())\n",
    "    fits = [fitness(x, ann, env) for x in solutions]\n",
    "    es.tell(solutions, fits)\n",
    "    es.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = es.result[0]\n",
    "-fitness(x, ann, env, visul=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The results on LunarLander clearly show the benefits of CMA-ES; we have found a reasonable policy in a small number of generations. Applying CMA-ES to larger neural networks remains an open challenge, however, due to the vast number of parameters in ANNs. Specifically, CMA-ES calculates the covariance of all parameters, which is $O(n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(es.sm.C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise 1</h3>\n",
    "    \n",
    "The network used has 2 layers of 32 neurons each. Try changing this and noticing the impact on the number of total parameters for CMA-ES. How large of a network can CMA-ES optimize?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise 2</h3>\n",
    "    \n",
    "Compare the $(1+\\lambda)$ ES, $(\\mu,\\lambda)$ ES, and CMA-ES algorithms on Lunar Lander. Is one significantly better than the others, consistently across different initializations?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
